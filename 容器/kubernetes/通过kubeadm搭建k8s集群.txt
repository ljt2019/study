
====== 通过 kubeadm 搭建k8s集群 ======

1、版本统一
  Docker       18.09.0
  ---
  kubeadm-1.14.0-0 
  kubelet-1.14.0-0 
  kubectl-1.14.0-0
  ---
  k8s.gcr.io/kube-apiserver:v1.14.0
  k8s.gcr.io/kube-controller-manager:v1.14.0
  k8s.gcr.io/kube-scheduler:v1.14.0
  k8s.gcr.io/kube-proxy:v1.14.0
  k8s.gcr.io/pause:3.1
  k8s.gcr.io/etcd:3.3.10
  k8s.gcr.io/coredns:1.3.1
  ---
  calico:v3.9
  
2、准备3台centos，要保证彼此之间能够ping通，也就是处于同一个网络中，虚拟机的配置要求上面也描述咯。

3、 更新并安装依赖，3台机器都需要执行
  【yum -y update】
  【yum install -y conntrack ipvsadm ipset jq sysstat curl iptables libseccomp】
  
4、安装Docker，三台机器都安装，安装步骤见docker安装笔记

5、修改hosts文件

  1)、master节点：【sudo hostnamectl set-hostname m】
  
  2)、两个worker分别
  【sudo hostnamectl set-hostname w1】
  【sudo hostnamectl set-hostname w2】
  
3、三个节点都在hosts文件上加上：【vi /etc/hosts】
  192.168.8.51 m
  192.168.8.61 w1
  192.168.8.62 w2
  
4、使用ping测试一下，【ping w1】

5、系统基础前提配置
  # (1)关闭防火墙
  systemctl stop firewalld && systemctl disable firewalld
  
  # (2)关闭selinux
  setenforce 0
  sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
  
  # (3)关闭swap
  swapoff -a
  sed -i '/swap/s/^\(.*\)$/#\1/g' /etc/fstab
  
  # (4)配置iptables的ACCEPT规则
  iptables -F && iptables -X && iptables -F -t nat && iptables -X -t nat && iptables -P FORWARD ACCEPT
  
  # (5)设置系统参数
  cat <<EOF >  /etc/sysctl.d/k8s.conf
  net.bridge.bridge-nf-call-ip6tables = 1
  net.bridge.bridge-nf-call-iptables = 1
  EOF
  
  sysctl --system
  
6、Installing kubeadm（搭建k8s集群）, kubelet（运行pod ） and kubectl（客户端与集群打交道的工具）

  1)、配置yum源，三个节点执行
  cat <<EOF > /etc/yum.repos.d/kubernetes.repo
  [kubernetes]
  name=Kubernetes
  baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
  enabled=1
  gpgcheck=0
  repo_gpgcheck=0
  gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
         http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
  EOF
  
  2)、安装kubeadm&kubelet&kubectl：【yum install -y kubeadm-1.14.0-0 kubelet-1.14.0-0 kubectl-1.14.0-0】

  3)、docker和k8s设置同一个cgroup
    (1)、【vi /etc/docker/daemon.json】，在/daemon.json文件中加入：【"exec-opts": ["native.cgroupdriver=systemd"],】
     【systemctl restart docker】
	
	(3)、# kubelet，这边如果发现输出directory not exist，也说明是没问题的，大家继续往下进行即可
     【sed -i "s/cgroup-driver=systemd/cgroup-driver=cgroupfs/g" /etc/systemd/system/kubelet.service.d/10-kubeadm.conf】
     
	(4)、安装成功，设置开机启动：【systemctl enable kubelet && systemctl start kubelet】

7、proxy/pause/scheduler等国内镜像

  1)、查看 kubeadm 使用的镜像：【kubeadm config images list】，内容如下，7个
    k8s.gcr.io/kube-apiserver:v1.14.0
    k8s.gcr.io/kube-controller-manager:v1.14.0
    k8s.gcr.io/kube-scheduler:v1.14.0
    k8s.gcr.io/kube-proxy:v1.14.0
    k8s.gcr.io/pause:3.1
    k8s.gcr.io/etcd:3.3.10
    k8s.gcr.io/coredns:1.3.1
	
  2)、解决国外镜像不能访问的问题
    (1)、创建kubeadm.sh脚本，用于拉取镜像/打tag/删除原有镜像，在每个节点中都创建保存改脚本：【vi kubeadm.sh】,内容如下
        #!/bin/bash
		
        set -e
		
        KUBE_VERSION=v1.14.0
        KUBE_PAUSE_VERSION=3.1
        ETCD_VERSION=3.3.10
        CORE_DNS_VERSION=1.3.1
        
        GCR_URL=k8s.gcr.io
        ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers
        
        images=(kube-proxy:${KUBE_VERSION}
        kube-scheduler:${KUBE_VERSION}
        kube-controller-manager:${KUBE_VERSION}
        kube-apiserver:${KUBE_VERSION}
        pause:${KUBE_PAUSE_VERSION}
        etcd:${ETCD_VERSION}
        coredns:${CORE_DNS_VERSION})
        
        for imageName in ${images[@]} ; do
          docker pull $ALIYUN_URL/$imageName
          docker tag  $ALIYUN_URL/$imageName $GCR_URL/$imageName
          docker rmi $ALIYUN_URL/$imageName
        done
		
    (2)、运行脚本和查看镜像：【sh ./kubeadm.sh】，【docker images】

  3)、将这些镜像推送到自己的阿里云仓库【可选，根据自己实际的情况】
    【docker login --username=xxx registry.cn-hangzhou.aliyuncs.com】，推送脚本如下
	
    #!/bin/bash
	
    set -e
	
    KUBE_VERSION=v1.14.0
    KUBE_PAUSE_VERSION=3.1
    ETCD_VERSION=3.3.10
    CORE_DNS_VERSION=1.3.1
    GCR_URL=k8s.gcr.io
    ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/tiger2019
    images=(kube-proxy:${KUBE_VERSION}
    kube-scheduler:${KUBE_VERSION}
    kube-controller-manager:${KUBE_VERSION}
    kube-apiserver:${KUBE_VERSION}
    pause:${KUBE_PAUSE_VERSION}
    etcd:${ETCD_VERSION}
    coredns:${CORE_DNS_VERSION})
    for imageName in ${images[@]} ; do
    	docker tag $GCR_URL/$imageName $ALIYUN_URL/$imageName
    	docker push $ALIYUN_URL/$imageName
    	docker rmi $ALIYUN_URL/$imageName
    done

    运行脚本 【sh ./kubeadm-push-aliyun.sh】

8、kube init初始化 master

  1)、kube init流程
  
    01-进行一系列检查，以确定这台机器可以部署kubernetes
    
    02-生成kubernetes对外提供服务所需要的各种证书可对应目录
    /etc/kubernetes/pki/*
    
    03-为其他组件生成访问kube-ApiServer所需的配置文件
        ls /etc/kubernetes/
        admin.conf  controller-manager.conf  kubelet.conf  scheduler.conf
        
    04-为 Master组件生成Pod配置文件。
        ls /etc/kubernetes/manifests/*.yaml
        kube-apiserver.yaml 
        kube-controller-manager.yaml
        kube-scheduler.yaml
        
    05-生成etcd的Pod YAML文件。
        ls /etc/kubernetes/manifests/*.yaml
        kube-apiserver.yaml 
        kube-controller-manager.yaml
        kube-scheduler.yaml
    	etcd.yaml
    	
    06-一旦这些 YAML 文件出现在被 kubelet 监视的/etc/kubernetes/manifests/目录下，kubelet就会自动创建这些yaml文件定义的pod，即master组件的容器。master容器启动后，kubeadm会通过检查localhost：6443/healthz这个master组件的健康状态检查URL，等待master组件完全运行起来
    
    07-为集群生成一个bootstrap token
    
    08-将ca.crt等 Master节点的重要信息，通过ConfigMap的方式保存在etcd中，工后续部署node节点使用
    
    09-最后一步是安装默认插件，kubernetes默认kube-proxy和DNS两个插件是必须安装的

  2)、【kubeadm init --kubernetes-version=1.14.0 --apiserver-advertise-address=192.168.3.51 --pod-network-cidr=10.244.0.0/16】
    1.执行成功信息
  Your Kubernetes control-plane has initialized successfully!
  
  To start using your cluster, you need to run the following as a regular user:
  
    mkdir -p $HOME/.kube
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config
  
  You should now deploy a pod network to the cluster.
  Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
    https://kubernetes.io/docs/concepts/cluster-administration/addons/
  
  Then you can join any number of worker nodes by running the following on each as root:
  
  kubeadm join 192.168.3.51:6443 --token fvxofu.fxdgrb9f6l5mvgmd \
      --discovery-token-ca-cert-hash sha256:db32c745032468fada5f50c218246951e098e3b09ef46696099a732d93cb92d5 

    
	2.根据日志提示执行：
      mkdir -p $HOME/.kube
      sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
      sudo chown $(id -u):$(id -g) $HOME/.kube/config
	  
	3.查看pod，等待一会儿，同时可以发现像etcd，controller，scheduler等组件都以pod的方式安装成功了
	
	4.查看kube-system的pods：【kubectl get pods -n kube-system -w】，注意：coredns没有启动，需要安装网络插件
	  查看所有pods：【kubectl get pods --all-namespaces】

    5.健康检查：【curl -k https://localhost:6443/healthz】

9、部署安装 calico 网络插件【https://kubernetes.io/docs/concepts/cluster-administration/addons/】

  1)、calico网络插件：【https://docs.projectcalico.org/v3.9/getting-started/kubernetes/】，calico，同样在master节点上操作
  
  2)、【kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml】
  
        可省略步骤：
      【wget https://docs.projectcalico.org/v3.9/manifests/calico.yaml】
	  查看所使用到的镜像：【cat calico.yaml | grep image】
	  

  3)、确认一下calico是否安装成功：【kubectl get pods --all-namespaces】，查看所有pods
  
  4)、主节点查询节点：【kubectl get node】

10、kube join，在woker01和worker02上执行之前保的命令，如下
  【kubeadm join 192.168.3.51:6443 --token 9s9lxo.zeijg5g35x1aex7m \
    --discovery-token-ca-cert-hash sha256:e7916a19e5c055acdf8f26aff67fb953efdfd7a55d78310cb258cf600dee9183】
  
  如果添加节点失败，或是想重新添加，可以在从节点使用命令：【kubeadm reset】
  
11、再次查看主节点：【kubectl get nodes】，此时发现多了节点信息

12、体验Pod，定义pod.yml文件，比如pod_nginx_rs.yaml
cat > pod_nginx_rs.yaml <<EOF
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx
  labels:
    tier: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      name: nginx
      labels:
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
EOF

13、根据pod_nginx_rs.yml文件创建pod：【kubectl apply -f pod_nginx_rs.yaml】

14、查看pod：
  【kubectl get pods】
  【kubectl get pods -o wide】，可以到对应节点查看验证：【docker ps | grep nginx】
  【kubectl describe pod nginx】
























  
  
